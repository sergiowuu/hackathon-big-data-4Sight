# Hackathon de Previs√£o de Vendas - Reposi√ß√£o de Estoque

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg) ![Pandas](https://img.shields.io/badge/Pandas-%26%20Polars-yellow.svg) ![LightGBM](https://img.shields.io/badge/LightGBM-4.0%2B-green.svg) ![Optuna](https://img.shields.io/badge/Optuna-3.0%2B-purple.svg)

## üìñ Vis√£o Geral

Este reposit√≥rio cont√©m a solu√ß√£o desenvolvida para o Hackathon Forecast da Big Data. O objetivo central √© criar um modelo de previs√£o de vendas (*forecast*) para otimizar a reposi√ß√£o de estoque no varejo. O c√≥digo analisa o hist√≥rico de vendas de 2022 para prever a demanda semanal por Ponto de Venda (PDV) e produto (SKU) para as cinco semanas de janeiro de 2023.

O modelo utiliza a t√©cnica de **Gradient Boosting** com a biblioteca **LightGBM**, otimizada com **Optuna** para encontrar os melhores hiperpar√¢metros, garantindo alta performance e efici√™ncia computacional.

---

## üéØ O Desafio

O problema proposto consiste em desenvolver uma solu√ß√£o de IA para prever a quantidade de vendas semanais, com base nos seguintes crit√©rios:

* **Objetivo:** Prever a quantidade de vendas por `PDV` e `SKU` para cada uma das 5 semanas de janeiro de 2023.
* **Dados de Treino:** Hist√≥rico transacional de vendas de 2022, enriquecido com dados cadastrais de produtos e PDVs.
* **M√©trica de Avalia√ß√£o:** A performance do modelo √© medida pelo **WMAPE** (Weighted Mean Absolute Percentage Error), que pondera os erros pela magnitude das vendas.
* **Crit√©rios Adicionais:** Qualidade t√©cnica do c√≥digo (clareza, organiza√ß√£o, documenta√ß√£o), criatividade na modelagem e supera√ß√£o de um modelo de *baseline* interno da empresa organizadora.

---

## üìä Dados

Foram disponibilizados tr√™s conjuntos de dados no formato `.parquet`:

1.  **`transacao.parquet`**: Cont√©m o hist√≥rico detalhado de cada transa√ß√£o realizada em 2022, incluindo IDs do PDV e do produto, data, quantidade e valores.
2.  **`produto.parquet`**: Tabela de cadastro com informa√ß√µes sobre cada produto (SKU), como categoria, marca e fabricante.
3.  **`pdv.parquet`**: Tabela de cadastro com informa√ß√µes sobre cada ponto de venda, como localiza√ß√£o e tipo de estabelecimento.

---

## ‚öôÔ∏è Metodologia Aplicada

A solu√ß√£o foi constru√≠da seguindo um pipeline estruturado de ponta a ponta, desde a leitura dos dados at√© a gera√ß√£o do arquivo final de submiss√£o.

#### 1. Limpeza e Pr√©-processamento de Dados
* Carregamento otimizado dos arquivos `.parquet` utilizando **Polars** e **Pandas**.
* Aplica√ß√£o de regras de neg√≥cio para remover dados inv√°lidos (ex: quantidades e valores negativos ou nulos).
* Tratamento de valores nulos nas colunas categ√≥ricas, preenchendo-os com a categoria `"Desconhecido"` para n√£o perder informa√ß√£o.
* Unifica√ß√£o das tr√™s bases em um √∫nico DataFrame mestre, pronto para a pr√≥xima fase.

#### 2. Engenharia de Features (Feature Engineering)
* **Agrega√ß√£o Semanal:** Os dados transacionais s√£o agregados por semana, PDV e produto para alinhar a granularidade dos dados com o objetivo da previs√£o.
* **Features Temporais:** M√™s e semana do ano s√£o extra√≠dos da data para capturar sazonalidades.
* **Lag Features:** Vendas da mesma combina√ß√£o PDV-SKU em semanas anteriores (lags de 1 a 4 semanas) s√£o criadas para informar ao modelo a tend√™ncia recente.
* **Features de Janela M√≥vel (Rolling Window):** M√©dia e desvio padr√£o das vendas nas √∫ltimas 4 semanas s√£o calculados para suavizar ru√≠dos e capturar a tend√™ncia e volatilidade.

#### 3. Otimiza√ß√£o de Hiperpar√¢metros com Optuna
* Antes do treinamento final, uma busca de hiperpar√¢metros √© realizada com **Optuna** para encontrar a melhor configura√ß√£o para o LightGBM.
* A busca √© feita de forma eficiente em uma **amostra representativa** dos dados (10%) para acelerar o processo.
* T√©cnicas avan√ßadas como **`GOSS` boosting** e **Pruning** (poda de `trials` ruins) s√£o utilizadas para garantir uma otimiza√ß√£o r√°pida e inteligente.

#### 4. Treinamento e Valida√ß√£o do Modelo
* **Modelo:** √â utilizado o **LightGBM (Light Gradient Boosting Machine)**, com os par√¢metros otimizados pelo Optuna.
* **Divis√£o dos Dados:** Foi adotada uma estrat√©gia de divis√£o estratificada por m√™s. **80% de cada m√™s** de 2022 √© usado para treino e **20% de cada m√™s** para teste. Isso garante que a sazonalidade esteja presente em ambos os conjuntos, tornando a valida√ß√£o mais robusta.
* **Tratamento de Categ√≥ricas:** As vari√°veis categ√≥ricas s√£o convertidas para o tipo `category` do Pandas, que √© tratado de forma nativa e altamente eficiente pelo LightGBM.

#### 5. Gera√ß√£o das Previs√µes
* O modelo final √© treinado com **todos os dados de 2022** utilizando os melhores par√¢metros encontrados.
* Um "esqueleto" de dados para as 5 semanas de janeiro de 2023 √© criado para os pares PDV-SKU ativos.
* As previs√µes s√£o geradas em um **loop autoregressivo**, onde a previs√£o da Semana 1 √© usada para calcular as features da Semana 2, e assim por diante.
* Os resultados s√£o tratados (valores negativos zerados, arredondados para inteiros) e formatados no arquivo de submiss√£o, respeitando o limite de 1.5M de linhas.

---

## üõ†Ô∏è Tecnologias e Bibliotecas

Para executar este projeto, √© necess√°rio ter o Python 3.9 (ou superior) instalado, juntamente com as seguintes bibliotecas.

* **`pandas`** e **`polars`**: Para manipula√ß√£o e an√°lise de dados.
* **`numpy`**: Para opera√ß√µes num√©ricas.
* **`scikit-learn`**: Para a divis√£o estrat√©gica dos dados.
* **`lightgbm`**: Para o treinamento do modelo de Gradient Boosting.
* **`optuna`**: Para a otimiza√ß√£o de hiperpar√¢metros.
* **`pyarrow`**: Depend√™ncia para ler arquivos `.parquet`.

Voc√™ pode instalar todas as depend√™ncias de uma vez usando o arquivo `requirements.txt`.
 
```bash
pip install -r requirements.txt
